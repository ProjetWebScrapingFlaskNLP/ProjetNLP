{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet NLP - Groupe 1 - Nohossat, Valérie, Williams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consignes\n",
    "\n",
    "Vous venez d'ouvrir un hôtel. Comme vous n'êtes pas sûr de la qualité de votre établissement, vous permettez aux personnes de poster des commentaires mais pas de mettre de note. Cependant, vous voulez quand même déterminer si le commentaire est positif ou négatif.  \n",
    "\n",
    "Pour cela, vous allez scrapper des commentaires sur booking et leur note associée afin de faire tourner un algorithme de classification pour faire des prédictions sur vos propres commentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "https://projetnlp.herokuapp.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Récuperation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site de référence : https://www.booking.com\n",
    "\n",
    "### Contraintes du scraping\n",
    "\n",
    "On a récupéré les commentaires des hôtels de plusieurs villes françaises telles que **Paris, Marseille, Lyon, etc...**  \n",
    "\n",
    "Booking ne permet pas d'ouvrir la page d'un hôtel dans le même onglet donc on a procédé en 2 temps :\n",
    "\n",
    "- Récupération des liens vers les hôtels avec des commentaires (on ignore ceux qui n'ont aucun commentaire)\n",
    "- Récupération des commentaires pour chaque hôtel présélectionné\n",
    "\n",
    "Cette démarche nous permet de reprendre le scraping en cas de crash puisque les liens vers les hôtels sont sauvegardés avant de passer à la deuxième étape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"1000px\" src='booking.gif' alt='booking_website'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données récupérées\n",
    "\n",
    "Pour chaque hôtel, on récupère au maximum 220 commentaires et les informations suivantes:\n",
    "\n",
    "- **NOM** : nom du client ayant laissé le commentaire\n",
    "- **PAYS** : pays de provenance du client\n",
    "- **FAVORITE** : est-ce que le client a marqué l'établissement parmi ces favoris ?\n",
    "- **DATE** : date d'envoi du commentaire\n",
    "- **TITRE** : titre du commentaire laissé par le client\n",
    "- **BONS POINTS** : les aspects positifs de l'expérience\n",
    "- **MAUVAIS POINTS** : les aspects négatifs de l'expérience\n",
    "- **NOTE** : la note laissée par le client\n",
    "- **TYPE ETABLISSEMENT**: le type de l'établissement (Appartement, Hôtel, etc..)\n",
    "- **LIEU** : Ville de l'établissement\n",
    "- **NOTE ETABLISSEMENT** : note moyenne laissée par l'ensemble des commentateurs\n",
    "\n",
    "<img width=\"600px\" src='commentaire_booking.png' alt='booking_commentaire'>\n",
    "\n",
    "### Résilience du scraping\n",
    "\n",
    "Plusieurs actions ont été mises en place pour rendre le scraping résilient: \n",
    "\n",
    "- relance de la page en cas d'apparition du pop-up 'Etes-vous humain?'\n",
    "- timeout de 8min pour récupérer les 220 commentaires par hôtel\n",
    "- multiprocessing (1 process par ville)\n",
    "- backup après chaque commentaire récupéré\n",
    "\n",
    "\n",
    "### Résultats\n",
    "\n",
    "Récupération de 30 946 commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc 30 946 lignes et 11 colonnes dans notre dataset.  \n",
    "\n",
    "Les statistiques descriptives ne sont pas concluantes parce que les colonnes sont pour la plupart du type string.\n",
    "\n",
    "Notre objectif est de savoir si un commentaire est positif ou négatif.   \n",
    "Pour cela, on doit se baser sur toutes les colonnes qui regroupent une partie du commentaire soit les colonnes :\n",
    "- **TITRE**, \n",
    "- **BONS POINTS**\n",
    "- **MAUVAIS POINTS**.\n",
    "\n",
    "On ne conservera que ces colonnes pour la suite de notre analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide de remplacer les valeurs nulles (‘None’, NaN) par des espaces vides.   \n",
    "Un espace vide correspond donc à une absence de commentaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nettoyage des données est nécessaire avant de pouvoir poursuivre l'analyse des commentaires. On va réaliser les actions suivantes : \n",
    "\n",
    "- Mettre les mots en minuscules\n",
    "- Supprimer la ponctuation\n",
    "- Supprimer les caractères numériques\n",
    "- Supprimer les mots dont la longueur est inférieure à 2\n",
    "- Supprimer les mots vides (conjonctions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fréquence des mots et nuage de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction orthographique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que faire des mots en anglais ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la polarité et de la subjectivité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qu'est-ce que la polarité ?\n",
    "\n",
    ">le commentaire envoyé est-il positif, négatif ou neutre ? \n",
    "\n",
    "La polarité est ce que l'on cherche à déterminer.\n",
    "\n",
    "#### Qu'est-ce que la subjectivité ?\n",
    "\n",
    "est-ce que le texte exprime une information objective ou est-ce qu’il donne une opinion subjective.\n",
    "\n",
    "**Pourquoi cherche-t-on a déterminer la subjectivité ?**\n",
    "\n",
    "Notre dataset final aura donc 2 colonnes: \n",
    "- variable indépendante : commentaire (concaténation des colonnes titre, bons points et mauvais points)\n",
    "- target : polarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 approches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Résultats et Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Conclusions et Difficultés rencontrées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "TBD\n",
    "\n",
    "#### Scraping\n",
    "\n",
    "- **gérer les coupures internet et les code recaptcha** : il faut relancer le process automatiquement après coupure ou lorsqu'un popup 'Etes-vous humain' empêche toute interaction.\n",
    "- **booking.com ouvre forcément les pages établissement sur un nouvel onglet**: cela ralentit le code puisqu'il faut prendre en compte le temps de latence et les codes intempésitfs de booking (cookie / recaptcha)\n",
    "- **gérer le multiprocessing** : pour récupérer le plus de données possibles, on a utilisé le multiprocessing. Mais on s'est rendu compte que la gestion des exceptions est ici primordiale parce que malgré les exceptions, le code doit continuer de scraper le site. Ce qui compte c'est d'en scraper le plus possible et non de pouvoir scrapper tous les commentaires existants. \n",
    "\n",
    "\n",
    "### Analyse des données\n",
    "\n",
    "TBD\n",
    "\n",
    "### Modélisation\n",
    "\n",
    "TBD\n",
    "\n",
    "### Création de l'application\n",
    "\n",
    "TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
