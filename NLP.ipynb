{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Import</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#import des librairies\n",
    "%pylab inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, auc, precision_score, recall_score\n",
    "from sklearn import feature_extraction, model_selection, svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore les warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des données\n",
    "#remplacement de None par NaN\n",
    "#décimal avec un point plutôt qu'une virgule dans le dataframe afin que les variables soient de type float\n",
    "df = pd.read_csv(r\"C:\\Users\\utilisateur\\Documents\\Projet\\ProjetNLP\\booking.csv\", na_values=['None'], decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>exceptionnel établissement recent propre soign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fabuleux accueil très chaleureux chambre calme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>exceptionnel tout bié sauf wifi catastrophique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>exceptionnel nan hôtel parfait quartier sympa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>fabuleux excellent rapport qualité prix person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentiment                                           sentence\n",
       "0           0          1  exceptionnel établissement recent propre soign...\n",
       "1           1          1  fabuleux accueil très chaleureux chambre calme...\n",
       "2           2          1  exceptionnel tout bié sauf wifi catastrophique...\n",
       "3           3          1      exceptionnel nan hôtel parfait quartier sympa\n",
       "4           4          1  fabuleux excellent rapport qualité prix person..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affichage des 5 premières lignes du dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Exploration et nettoyage des données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset a 30946 lignes et 3 colonnes.\n"
     ]
    }
   ],
   "source": [
    "#dimensions du dataframe\n",
    "print('Le dataset a {} lignes et {} colonnes.'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différents variables sont : ['Unnamed: 0', 'sentiment', 'sentence'].\n"
     ]
    }
   ],
   "source": [
    "#affichage des variables\n",
    "print('Les différents variables sont : {}.'.format(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Existe-t-il des variables non renseignées?\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "sentiment     0\n",
       "sentence      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affichage du nombre de valeurs manquantes selon chaque variable\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "sentiment      int64\n",
       "sentence      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type de chaque variable\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30946.000000</td>\n",
       "      <td>30946.000000</td>\n",
       "      <td>30940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exceptionnel client  laissé commentaire nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15472.500000</td>\n",
       "      <td>0.830899</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8933.485052</td>\n",
       "      <td>0.374847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7736.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15472.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23208.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30945.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0     sentiment  \\\n",
       "count   30946.000000  30946.000000   \n",
       "unique           NaN           NaN   \n",
       "top              NaN           NaN   \n",
       "freq             NaN           NaN   \n",
       "mean    15472.500000      0.830899   \n",
       "std      8933.485052      0.374847   \n",
       "min         0.000000      0.000000   \n",
       "25%      7736.250000      1.000000   \n",
       "50%     15472.500000      1.000000   \n",
       "75%     23208.750000      1.000000   \n",
       "max     30945.000000      1.000000   \n",
       "\n",
       "                                           sentence  \n",
       "count                                         30940  \n",
       "unique                                        26290  \n",
       "top     exceptionnel client  laissé commentaire nan  \n",
       "freq                                            417  \n",
       "mean                                            NaN  \n",
       "std                                             NaN  \n",
       "min                                             NaN  \n",
       "25%                                             NaN  \n",
       "50%                                             NaN  \n",
       "75%                                             NaN  \n",
       "max                                             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistiques descriptives du dataset\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des accents\n",
    "#cols = df.select_dtypes(include=[np.object]).columns\n",
    "#df[cols] = df[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction pour générer un nuage de mots\n",
    "def wcloud(data,bgcolor,title):\n",
    "    plt.figure(figsize = (100,100))\n",
    "    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n",
    "    wc.generate(' '.join(data))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itération sur l'ensemble des lignes du dataframe, affichache de l'index et son commentaire associé\n",
    "#for index, row in df.iterrows():\n",
    "    #print('index: ', index, 'col sentences:', row['titre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itération sur l'ensemble des lignes du dataframe, affichache de l'index et son commentaire associé\n",
    "#for index, row in df.iterrows():\n",
    "    #print('index: ', index, 'col sentences:', row['bons_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itération sur l'ensemble des lignes du dataframe, affichache de l'index et son commentaire associé\n",
    "#for index, row in df.iterrows():\n",
    "    #print('index: ', index, 'col sentences:', row['bons_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str = \"ÊÎÔÛÄËÏÖÜÀÆæÇÉÈŒœÙ!!!\";\n",
    "#print(str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'titre'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'titre'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8681e1b91542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#str.lower : mettre tous les éléments en minuscule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#str.cat : concaténation des strings avec le séparateur donné en paramètre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'titre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#supprimer ponctuation, nombres et retourner une liste de mots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'titre'"
     ]
    }
   ],
   "source": [
    "#str.lower : mettre tous les éléments en minuscule\n",
    "#str.cat : concaténation des strings avec le séparateur donné en paramètre\n",
    "a = df['titre'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "#supprimer ponctuation, nombres et retourner une liste de mots\n",
    "b = re.sub('[^a-zàâéèêëïîôùûçæœ]+', ' ', a)\n",
    "\n",
    "#supprimer tous les mots \"vides\" du texte\n",
    "stop_words = list(get_stop_words('french'))         \n",
    "nltk_words = list(stopwords.words('french'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens = word_tokenize(b)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#supprimer les mots qui ont une longueur inférieure à 2  \n",
    "without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
    "\n",
    "#suppression des caractères numériques\n",
    "cleaned_data = [word for word in without_single_chr if not word.isnumeric()]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les 100 mots les plus fréquents\n",
    "top_N = 100\n",
    "word_dist = nltk.FreqDist(cleaned_data)\n",
    "rslt = pd.DataFrame(word_dist.most_common(top_N), columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage dans un dataframe des 7 mots les plus fréquents\n",
    "rslt.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogramme des 7 mots les plus fréquents\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuage de mots\n",
    "wcloud(cleaned_data,'black','Common Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre tous les éléments en miniscule, séparés par un espace\n",
    "a = df['bons_points'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "#supprimer ponctuation, nombres and retourner une liste de mots\n",
    "b = re.sub('[^a-zàâéèêëïîôùûç]+', ' ', a)\n",
    "\n",
    "#supprimer tous les mots \"vides\" du texte\n",
    "stop_words = list(get_stop_words('french'))         \n",
    "nltk_words = list(stopwords.words('french'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens = word_tokenize(b)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#supprimer les mots qui ont une longueur inférieure à 2  \n",
    "without_single_chr = [word for word in filtered_sentence if len(word) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supprimer les caractères numériques\n",
    "cleaned_data = [word for word in without_single_chr if not word.isnumeric()]        \n",
    "\n",
    "#calculer les 100 mots les plus fréquents\n",
    "top_N = 100\n",
    "word_dist = nltk.FreqDist(cleaned_data)\n",
    "rslt = pd.DataFrame(word_dist.most_common(top_N), columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage dans un dataframe des 7 mots les plus fréquents\n",
    "rslt.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogramme des 7 mots les plus fréquents\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuage de mots\n",
    "wcloud(cleaned_data,'black','Common Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre tous les éléments en miniscule, séparés par un espace\n",
    "a = df['mauvais_points'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "#supprimer ponctuation, nombres and retourner une liste de mots\n",
    "b = re.sub('[^A-Za-zàâéèêëïîôùûç]+', ' ', a)\n",
    "\n",
    "#supprimer tous les mots \"vides\" du texte\n",
    "stop_words = list(get_stop_words('french'))         \n",
    "nltk_words = list(stopwords.words('french'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens = word_tokenize(b)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#supprimer les mots qui ont une longueur inférieure à 2  \n",
    "without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
    "\n",
    "#supprimer caractères numériques\n",
    "cleaned_data = [word for word in without_single_chr if not word.isnumeric()]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supprimer caractères numériques\n",
    "cleaned_data = [word for word in without_single_chr if not word.isnumeric()]        \n",
    "\n",
    "#calculer les 100 mots les plus fréquents\n",
    "top_N = 100\n",
    "word_dist = nltk.FreqDist(cleaned_data)\n",
    "rslt = pd.DataFrame(word_dist.most_common(top_N), columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage dans un dataframe des 7 mots les plus fréquents\n",
    "rslt.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogramme des 7 mots les plus fréquents\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuage de mots\n",
    "wcloud(cleaned_data,'black','Common Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérification que les NaN dans la colonne 'mauvais points' ont bien de façon certaine une polarité de zéro pour TextBlob, \n",
    "#sentiment[0]=polarite et sentiment[1]=subjectivité\n",
    "#text = u\"NaN\"\n",
    "#blob = TextBlob(text, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "#blob.sentiment\n",
    "#print('NaN a une polarité de {} et une subjectivité de {}.'.format(blob.sentiment[0], blob.sentiment[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des Nan\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression de deux phrases récurrentes dans les données\n",
    "df = df[df.bons_points != \"Ce commentaire n'apparaît pas car il ne respecte pas notre charte.\"]\n",
    "df = df[df.bons_points != \"Ce client n'a pas laissé de commentaire.\"]\n",
    "\n",
    "df = df[df.mauvais_points != \"Ce commentaire n'apparaît pas car il ne respecte pas notre charte.\"]\n",
    "df = df[df.mauvais_points != \"Ce client n'a pas laissé de commentaire.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concaténation des trois colonnes correspondant aux commentaires sur les hôtels\n",
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "df22 = pd.DataFrame(df, columns= ['titre', 'bons_points', 'mauvais_points'])\n",
    "\n",
    "df21 = df22['titre'].map(str) + ' ' + df22['bons_points'].map(str) + ' ' + df22['mauvais_points'].map(str)\n",
    "\n",
    "#print(df21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir series en dataframe\n",
    "df21 = df21.to_frame(name=\"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mettre les commentaires du dataframe en miniscule\n",
    "df21['sentences']=df21['sentences'].str.lower()\n",
    "df21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remplacement de tout ce qui n'est pas dans le set[] par un espace\n",
    "df21['sentences'] = df21['sentences'].apply(lambda x: re.sub('[^a-zàâéèêëïîôùûçæœ-]+',' ', str(x))) \n",
    "#for index, row in df21.iterrows():\n",
    "    #print('index: ', index, 'col sentences:', row['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des mots d'une longueur inférieure à 2 caractères\n",
    "#\\b=la fin et le début d'un mot\n",
    "#`r' ou`R': préfixe pour les chaines de caractère \n",
    "df21['sentences']=df21.sentences.str.replace(r'\\b(\\w{1,2})\\b', '')\n",
    "#for index, row in df21.iterrows():\n",
    "    #print('index: ', index, 'col sentences:', row['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22=df21.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existe-t-il des variables numériques?\n",
    "df21['sentences'].apply(lambda x: not any(i.isnumeric() for i in x.split())).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df21['sentences'].str.contains(r'[0-9]').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des commentaires dans le type series\n",
    "df21 = df21['sentences']\n",
    "type(df21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul de la polarité des commentaires avec TextBlob\n",
    "bloblist_desc = list()\n",
    "\n",
    "df_str=df21.astype(str)\n",
    "for row in df_str:\n",
    "    blob = TextBlob(row)\n",
    "    #print(blob)\n",
    "    pos_tagger=PatternTagger()\n",
    "    analyzer=PatternAnalyzer()\n",
    "    blob = tb(str(blob)) #textblob\n",
    "    #sentiment renvoie un tuple avec la polarité et la subjectivite\n",
    "    #print(blob.sentiment[0])\n",
    "    #type(blob.sentiment[0])\n",
    "    bloblist_desc.append(blob.sentiment[0])\n",
    "    #df_polarity_desc1 = pd.DataFrame(bloblist_desc, columns = ['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des résultats de la polarité dans un dataframe\n",
    "df_polarity_desc1 = pd.DataFrame(data = bloblist_desc)\n",
    "df_polarity_desc1.columns = ['sentiment']\n",
    "df_polarity_desc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification des commentaires selon trois modalités (neutres, positifs et négatifs) dans un dataframe\n",
    "def f(df_polarity_desc1):\n",
    "    if df_polarity_desc1['sentiment'] > 0:\n",
    "        val = \"positive\"\n",
    "    elif df_polarity_desc1['sentiment'] < 0:\n",
    "        val = \"negative\"\n",
    "    else :\n",
    "        val = \"neutre\"\n",
    "    return val\n",
    "\n",
    "df_polarity_desc1.apply(f, axis=1)\n",
    "df_polarity_desc1['polarite']=df_polarity_desc1.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_desc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de masse de la polarité des commentaires\n",
    "num_bins = 50\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(df_polarity_desc1.sentiment, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of polarity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxenplot de la polarité des commenatires, boxplot avec plus de quartiles\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxenplot(x='polarite', y='sentiment', data=df_polarity_desc1)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countplot des modalités correspondant à la polarité des commentaires\n",
    "df_polarity_desc1.head()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.countplot(x=\"polarite\", data=df_polarity_desc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagramme circulaire des modalités de la polarité des commentaires\n",
    "pourcentage_positive = round(len(df_polarity_desc1.loc[(df_polarity_desc1.polarite == \"positive\")])) / len(df_polarity_desc1)\n",
    "pourcentage_negative = round(len(df_polarity_desc1.loc[(df_polarity_desc1.polarite == \"negative\")])) / len(df_polarity_desc1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "plt.title(\"Pourcentage des commentaires positifs vs négatifs\", fontsize=18)\n",
    "labels = ['positif', 'négatif']\n",
    "sizes = [pourcentage_positive, pourcentage_negative]\n",
    "#explode = (0, 0.2)  # seulement détacher le second groupe\n",
    "\n",
    "patches, texts, autotexts = ax1.pie(sizes,  labels=labels, autopct='%1.1f%%', shadow = True, startangle=130, colors = ['#00e64d', 'r'])\n",
    "texts[0].set_fontsize(15)\n",
    "texts[1].set_fontsize(15)\n",
    "\n",
    "matplotlib.rcParams['text.color'] = 'black'\n",
    "matplotlib.rcParams[\"font.size\"] = 18\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\utilisateur\\Documents\\Projet\\ProjetNLP\\booking.csv\", na_values=['None'], decimal=',')\n",
    "df_notes = df.iloc[:,7]\n",
    "#df_notes = pd.DataFrame(data=df_notes)\n",
    "df_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_desc1_polarite = df_polarity_desc1.iloc[:,1]\n",
    "#df_polarity_desc1_polarite = pd.DataFrame(df_polarity_desc1_polarite)\n",
    "df_polarity_desc1_polarite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.concat([df_polarity_desc1_polarite, df_notes], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_corr.loc[(df_corr.polarite=='positive')|(df_corr.polarite=='negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr['polarite'] = np.where(df_corr['polarite'] == 'positive', 1, 0)\n",
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage des corrélations entre variables\n",
    "#parfaite si r = 1\n",
    "#très forte si r > 0,8\n",
    "#forte si r se situe entre 0,5 et 0,8\n",
    "#d'intensité moyenne si r se situe entre 0,2 et 0,5\n",
    "#faible si r se situe entre 0 et 0.2\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "plt.title('Correlation entre variables')\n",
    "sns.heatmap(df_corr.corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"YlGnBu\", linecolor='black', annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_desc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_desc1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation des valeurs de la variable polarite en 1 et 0\n",
    "#pas besoin d'utiliser le module scikit-learn car on peut le faire directement \n",
    "df_polarity_desc1['polarite'] = np.where(df_polarity_desc1['polarite'] == 'positive', 1, 0)\n",
    "df_polarity_desc1 = df_polarity_desc1.reset_index(drop=True)\n",
    "df_polarity_desc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_desc1.drop(['sentiment'],1,inplace=True)\n",
    "df_polarity_desc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df21.head()\n",
    "comments = pd.DataFrame(data=df21)\n",
    "comments.columns = ['sentences']\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion des deux datasets en un seul que l'on nommera df\n",
    "df = pd.concat([df_polarity_desc1, comments], axis = 1)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['sentiment', 'sentence']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()\n",
    "df.isnull().sum()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DatasetMachineLearning.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Machine learning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['sentence']], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
    "pipe.fit(X_train['sentence'])\n",
    "feat_train = pipe.transform(X_train['sentence'])\n",
    "feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train.min(), feat_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test = pipe.transform(X_test['sentence'])\n",
    "feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(feat_train, y_train)\n",
    "dt.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree = dt.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatriceConfusion (model):\n",
    "    y_pred = model.predict(feat_test)\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Matrice de confusion', y=1.12)\n",
    "    plt.colorbar()\n",
    "    print(cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth' : [40, 60],\n",
    "             'n_estimators' : [30, 50, 200]}\n",
    "grid = GridSearchCV( RandomForestClassifier(), param_grid, cv = 3)\n",
    "\n",
    "%time grid.fit(feat_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "yfit = model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=30, max_depth=40, random_state=42)\n",
    "clf = clf.fit(feat_train, y_train)\n",
    "clf.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict_proba(feat_test)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict_proba(feat_test)\n",
    "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "aucf = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
    "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(feat_train, y_train)\n",
    "lr.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test\n",
    "'''ROC curve'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "lr = lr.fit(feat_train, y_train)\n",
    "y_score = lr.decision_function(feat_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(feat_train, y_train)\n",
    "mnb.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivebayes = nb.BernoulliNB()\n",
    "naivebayes.fit(feat_train, y_train)\n",
    "naivebayes.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc40 = GradientBoostingClassifier()\n",
    "param_grid = {'max_depth' : [40, 60],\n",
    "             'n_estimators' : [30, 50, 200]}\n",
    "grid = GridSearchCV( RandomForestClassifier(), param_grid, cv = 3)\n",
    "\n",
    "%time grid.fit(feat_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "yfit = model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc40 = GradientBoostingClassifier(n_estimators=40, max_depth=30)\n",
    "gbc40.fit(feat_train, y_train)\n",
    "gbc40.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "# defining parameter range\n",
    "param_grid = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "clf = svm.SVC()\n",
    "clf_grid = GridSearchCV(clf, param_grid, refit = True, verbose = 3,cv=3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "svm = clf_grid.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "# defining parameter range\n",
    "param_grid = {'C': [10, 50, 100,200],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','sigmoid']\n",
    "             }\n",
    "clf = svm.SVC()\n",
    "clf_grid = GridSearchCV(clf, param_grid, refit = True, verbose = 3,cv=3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "svm = clf_grid.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_grid.best_score_.round(2))\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = final_model.predict(feat_train) \n",
    "pred_test = final_model.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# print classification report\n",
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes as nb\n",
    "naivebayes = nb.BernoulliNB()\n",
    "\n",
    "naivebayes_fit = naivebayes.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = naivebayes.predict(feat_train)\n",
    "pred_test = naivebayes.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(naivebayes_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc40 = GradientBoostingClassifier(n_estimators=200, max_depth=40)\n",
    "gbc40.fit(feat_train, y_train)\n",
    "gbc40.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
    "list(generated_ngrams)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
    "                      TfidfTransformer())\n",
    "pipe2.fit(X_train['sentence'])\n",
    "feat_train2 = pipe2.transform(X_train['sentence'])\n",
    "feat_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pipe2.steps[0]\n",
    "cl[1].get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test2 = pipe2.transform(X_test['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(feat_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.score(feat_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
    "pipe_svd.fit(X_train['sentence'])\n",
    "feat_train_svd = pipe_svd.transform(X_train['sentence'])\n",
    "feat_train_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svd = RandomForestClassifier(n_estimators=50, max_depth=40, random_state=42)\n",
    "clf_svd.fit(feat_train_svd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test_svd = pipe_svd.transform(X_test['sentence'])\n",
    "clf_svd.score(feat_test_svd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_svd = LogisticRegression()\n",
    "lr_svd.fit(feat_train_svd, y_train)\n",
    "lr_svd.score(feat_test_svd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svd_tfidf = make_pipeline(CountVectorizer(),\n",
    "                     TfidfTransformer(),\n",
    "                     TruncatedSVD(n_components=300))\n",
    "pipe_svd_tfidf.fit(X_train['sentence'])\n",
    "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentence'])\n",
    "\n",
    "clf_svd_tfidf = LogisticRegression()\n",
    "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
    "\n",
    "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentence'])\n",
    "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentence']]\n",
    "sentance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
    "                          min_count=2, workers=1, iter=100)\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab\n",
    "list(vocab)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['exceptionnel'].shape, model.wv['exceptionnel'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vect(word, model):\n",
    "    try:\n",
    "        return model.wv[word]\n",
    "    except KeyError:\n",
    "        return numpy.zeros((model.vector_size,))\n",
    "\n",
    "def sum_vectors(phrase, model):\n",
    "    return sum(get_vect(w, model) for w in phrase)\n",
    "\n",
    "def word2vec_features(X, model):\n",
    "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
    "    return feats\n",
    "\n",
    "wv_train_feat = word2vec_features(X_train[\"sentence\"], model)\n",
    "wv_train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfwv = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clfwv.fit(wv_train_feat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_test_feat = word2vec_features(X_test[\"sentence\"], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfwv.score(wv_test_feat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(sorted(model.wv.vocab))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['exceptionnel', 'personnel', words[3], words[4], words[5]]\n",
    "rows = []\n",
    "for w in subset:\n",
    "    for ww in subset:\n",
    "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
    "import pandas\n",
    "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y variable dépendante et X variables indépendantes\n",
    "#X = df.iloc[:, df.columns !='polaritecomments'].values\n",
    "#y = df.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "#print (X_train.shape,y_train.shape)\n",
    "#print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.hist(figsize=(13,50),color='blue',bins=40,layout=(8,3))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'max_depth' : [3, 10, 15],\n",
    "#    'random_state': [0, 42],\n",
    "#             'n_estimators' : [10, 50]}\n",
    "#grid = GridSearchCV( RandomForestClassifier(), param_grid)\n",
    "\n",
    "#%time grid.fit(X_train, y_train)\n",
    "#print(grid.best_params_)\n",
    "\n",
    "#model = grid.best_estimator_\n",
    "#yfit = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = (y == 0).sum() / (1.0 * (y == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_score(model,X_train,X_test,y_train,y_test):\n",
    "    #model.fit(X_train,y_train)\n",
    "    #return model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "SVM = SVC()\n",
    "NB = nb.BernoulliNB()\n",
    "DTC = DecisionTreeClassifier(max_depth = 5, random_state= 42)\n",
    "RF = RandomForestClassifier(max_depth = 5, n_estimators= 10, random_state= 42)\n",
    "XGBC = XGBClassifier(max_depth = 5, scale_pos_weight = weights, \\\n",
    "                n_jobs = 4)\n",
    "\n",
    "logis=list()\n",
    "svm=list()\n",
    "nb=list()\n",
    "arb=list()\n",
    "rfl=list()\n",
    "clf=list()\n",
    "\n",
    "for index_train, index_test in kf.split(d_model):\n",
    "    X_train, X_test, y_train, y_test = X[index_train], X[index_test], y[index_train], y[index_test]\n",
    "    logis.append(get_score(LR, X_train, X_test, y_train, y_test))\n",
    "    svm.append(get_score(SVM, X_train, X_test, y_train, y_test))\n",
    "    nb.append(get_score(NB, X_train, X_test, y_train, y_test))\n",
    "    arb.append(get_score(DTC, X_train, X_test, y_train, y_test))\n",
    "    rfl.append(get_score(RF, X_train, X_test, y_train, y_test))\n",
    "    clf.append(get_score(XGBC, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "print(np.mean(logis))\n",
    "print(np.mean(svm))\n",
    "print(np.mean(arb))\n",
    "print(np.mean(rfl))\n",
    "print(np.mean(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y variable dépendante et X variables indépendantes\n",
    "X = d_model.iloc[:, d_model.columns !='isFraud']\n",
    "Y = d_model.iloc[:, 5]\n",
    "\n",
    "X_t = pd.DataFrame(X_train)\n",
    "feature_importances = pd.DataFrame(RF.feature_importances_, index = X.columns,columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "importances=RF.feature_importances_\n",
    "indices=np.argsort(importances)\n",
    "plt.barh(range(len(indices)), importances[indices])\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('importance du score');\n",
    "plt.ylabel('variables indépendantes');\n",
    "plt.title('Ordre d\\'importance des variables indépendantes');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatriceConfusion (model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Matrice de confusion', y=1.12)\n",
    "    plt.colorbar()\n",
    "    print(cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MatriceConfusion(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaiveBayes = muticlasses\n",
    "#SVM = multiclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
